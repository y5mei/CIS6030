# Assignment4 K-Mean vs HDBSCAN
 Yaowen Mei (1177855)

---
## Step-0: Setup Hadoop Docker and start the name node
I am basically following [this medium post](https://towardsdatascience.com/hdfs-simple-docker-installation-guide-for-data-science-workflow-b3ca764fc94b) in this step.


---
## Dive Deep Before We Start Implementing HDBSCAN
All the code and plots in this section are [in this Colab file.](https://colab.research.google.com/drive/1BXKsXtT_O_wn7GgpCXZYLKAUXXeKEyvQ?usp=sharing) Anyone click this link has access as commenter.
#### 1. First, let's have a overlook of the multishapes dataset
![overlook](pics/overlook.png "Overlook of the dataset")
The first thing we notice is that the smallest cluster is cluster 6 with size of 50 pts, which means our <span style="color:red"> **MCS** parameter should not greater than 50</span>
, otherwise, cluster 6 will be treated as noise points, which does not make sense. 

#### 2. Second, let's see how DBSCAN (not HDBSCAN) solve K-Mean's problem on this dataset
We have already seen that K-Mean did a bad job in clustering this dataset due to the fact of
* difference points density
* difference cluster size
* Non-round cluster shape

Let's have a quick look at how good the standard DBSCAN lib can solve this problem:
![dbscan](pics/dbscan.png "DBSCAN of the dataset")

As we can see from the picture above, on the upper-left corner, DBSCAN did a good job in clustering this dataset; However,
this clustering is not stable respect to `eps` parameter and `minPts` parameter. 

I have increased eps value from 0.15 to 0.45 in the row direction, and incrased minPts from 5 to 15 in col direction,
as we can see DBSCAN is returning non-idea result in each case.

#### 3. Third, have a quick look at the performance of the `hdbscan` implemented in `dbscan` CRAN library

Surprisingly, the [off-the-shelf implementation of `hdbscan`](https://cran.r-project.org/web/packages/dbscan/vignettes/hdbscan.html) didn't perform well for this dataset.
Please note that the current `hdbsan` implementation in R has only one parameter, `minPts`, which is the `min cluster size`, and is also the `min points` involved to calculate core-distance.

The justification of making `min points` equals `min cluster size` is given in [Campello's origin 2013 paper](https://link.springer.com/chapter/10.1007/978-3-642-37456-2_14):
> To make HDBSCAN more similar to previous density-based approaches and to simplify its use, we can set mclSize = mpts, which turns mpts into a single parameter that acts as both a smoothing factor and a threshold for the cluster size.

As you can see blew, I have tried different `minPts` values from 2 to 60, but none of results is reasonable.

![current_hdbscan](pics/current_hdbscan.png "Current HDBSCAN of the dataset")

To be honest, I do not really think this dataset can have a reasonable (Robust) clustered result generated by HDBSCAN,
but, anyways, I am going to try to make `min points` **NOT** equal to `min cluster size` in my HDBSCAN implementation 
so that I will obtain an extra hyperparameter to tweak. 
Hopefully this will make my result better than this off-the-shelf solution.
---